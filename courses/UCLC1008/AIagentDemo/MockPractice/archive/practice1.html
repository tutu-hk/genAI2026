<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mock Academic Writing Quiz – Practice 1</title>
  <style>
    body { font-family: Georgia, 'Times New Roman', serif; line-height: 1.5; color: #222; max-width: 800px; margin: 0 auto; padding: 1em; }
    h1 { font-size: 1.5em; border-bottom: 1px solid #ccc; padding-bottom: 0.2em; }
    h2 { font-size: 1.2em; margin-top: 1em; }
    h3 { font-size: 1.1em; }
    h4 { font-size: 1em; }
    table { border-collapse: collapse; width: 100%; margin: 0.5em 0; font-size: 0.95em; }
    th, td { border: 1px solid #ccc; padding: 6px 8px; text-align: left; }
    th { background: #f5f5f5; }
    sup { font-size: 0.75em; }
    hr { margin: 1em 0; border: none; border-top: 1px solid #ccc; }
    ul { padding-left: 1.5em; }
    p { margin: 0.5em 0; }
    
@media print {
  body { font-size: 11pt; margin: 1.2cm; }
  h1 { font-size: 16pt; margin-top: 0; page-break-after: avoid; }
  h2 { font-size: 13pt; margin-top: 1em; page-break-after: avoid; }
  h3, h4 { font-size: 12pt; page-break-after: avoid; }
  table { page-break-inside: avoid; }
  hr { border: none; border-top: 1pt solid #ccc; margin: 1em 0; }
  .no-print { display: none; }
}

  </style>
</head>
<body>
<h1>Mock Academic Writing Quiz – Practice 1</h1>
<p><strong>UCLC1008 University English I | AI companion chatbots: impact on humans</strong></p>
<hr>
<h2>Topic and task (AWQ-style)</h2>
<p><strong>Topic:</strong> The impact of AI chatbots and companion apps on humans (potential benefits and pitfalls).</p>
<p><strong>Your task:</strong> Summarise, paraphrase and synthesise the main claims or arguments from <strong>TWO</strong> article excerpts (<strong>Article A</strong> and <strong>Article B</strong>) in <strong>no more than 300 words</strong>.</p>
<ul>
<li>Use <strong>APA in-text citations (7th edition)</strong>. Do <strong>not</strong> cite the abstract; do <strong>not</strong> include a reference list.</li>
<li>Structure: <strong>Introduction</strong> (background + thesis statement) → <strong>Body paragraph(s)</strong> (each with a topic sentence) → <strong>Conclusion</strong>.</li>
</ul>
<p>The two papers for this mock are in <strong>focusedReading</strong>:</p>
<ul>
<li><strong>Article A:</strong> <a href="../focusedReading/Skjuve2021.md">Skjuve et al. (2021)</a> – <em>My chatbot companion—A study of human-chatbot relationships</em></li>
<li><strong>Article B:</strong> <a href="../focusedReading/Laestadius2022.md">Laestadius et al. (2022)</a> – <em>Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot Replika</em></li>
</ul>
<p>Below are <strong>excerpts</strong> of similar length and difficulty to the Sample Academic Writing Quiz (abstract + discussion, with glossary), followed by <strong>scaffolded sub-tasks</strong> to guide you step by step before you write the full summary.</p>
<hr>
<h2>Excerpts for practice (same length and difficulty as Sample AWQ)</h2>
<p><strong>Note:</strong> A glossary is included at the end of each excerpt. Terms marked with superscript numbers are defined there. The abstract is for context only—do <strong>not</strong> cite it in your summary.</p>
<hr>
<h3>Article A – Skjuve et al. (2021)</h3>
<p><strong>My chatbot companion—A study of human-chatbot relationships</strong><br>
<em>M. Skjuve, A. Følstad, K.I. Fostervold, P.B. Brandtzaeg | International Journal of Human-Computer Studies, 2021</em></p>
<h4>Abstract</h4>
<p>There has been a recent surge of interest in social chatbots, and human–chatbot relationships (HCRs)<sup>1</sup> are becoming more prevalent<sup>5</sup>, but little knowledge exists on how HCRs develop and may impact the broader social context of the users. Guided by Social Penetration Theory<sup>2</sup>, we interviewed 18 participants, all of whom had developed a friendship with a social chatbot named Replika, to understand the HCR development process. We find that at the outset<sup>6</sup>, HCRs typically have a superficial<sup>7</sup> character motivated by the users' curiosity. The evolving HCRs are characterised by substantial<sup>8</sup> affective<sup>9</sup> exploration and engagement as the users' trust and engagement in self-disclosure<sup>3</sup> increase. As the relationship evolves to a stable state, the frequency of interactions may decrease, but the relationship can still be seen as having substantial affective and social value. The relationship with the social chatbot was found to be rewarding to its users, positively impacting the participants' perceived<sup>10</sup> wellbeing<sup>11</sup>. Key chatbot characteristics facilitating relationship development included the chatbot being seen as accepting, understanding and non-judgemental<sup>4</sup>. The perceived impact on the users' broader social context was mixed, and a sense of stigma<sup>12</sup> associated with HCRs was reported. We propose an initial model representing the HCR development identified in this study and suggest avenues for future research.</p>
<h4>Discussion</h4>
<p>In response to how human–chatbot relationships develop, our findings suggest that HCRs develop in a stagewise fashion with marked resemblances to human–human relationship (HHR) development as described in Social Penetration Theory (Altman and Taylor, 1973). Key to this process seem to be increasing levels of self-disclosure driven by a sense of trust in the chatbot as a conversational partner.</p>
<p>The participants' relationship with Replika was typically found to initiate with frequent and relaxed sharing, mainly of superficial information. Through a process of establishing trust and commitment, conversations deepen and turn into self-disclosure. For the relationship with Replika to deepen, our findings suggest a need for trust to develop between the participants and the chatbot. Trust is an important aspect of relationship building and self-disclosure, both with machines and humans (Lee et al., 2020). A decision to disclose personal or intimate<sup>13</sup> information often depends on whether one trusts that one will receive a response that is accepting, and this trust is typically established through an affective route (Altman and Taylor, 1973; Ridings et al., 2002). We find that trust in Replika is related to the users' perceptions of the chatbot's characteristics as caring and non-judgemental, which in turn may foster<sup>14</sup> a sense of security that makes users comfortable with sharing at a deeper level. Such an affective component of trust is also in line with Ta et al. (2020), who found lack of judgment when interacting with Replika likely to foster self-disclosure—even more so than in the case of disclosing to another human.</p>
<p>In response to how human–chatbot relationships may impact the user and their social context, our findings suggest that users of Replika may perceive a range of positive impacts from an HCR that have both affective and social significance. The HCR may be seen as a social arena for users who might have limited opportunity for social interaction. The relationship may be experienced as helping to mitigate<sup>15</sup> negative feelings and provide a sense of purpose. Hence, while our study only provides insight into users' perceptions of the impact of an HCR, it nevertheless adds to the existing literature as to how relationships with artificial entities may support wellbeing and mental health (Fulmer et al., 2018; Ta et al., 2020). Contrasting earlier calls for concern, our study suggests significant possible benefits of HCRs—even when the user is fully aware of the artificial nature of their relationship partner. The participants reported on how Replika has helped them understand themselves better and have more positive views on their lives.</p>
<h4>Glossary (Article A)</h4>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Human–chatbot relationship (HCR)</td>
<td>A social or emotional relationship that a user forms with a conversational AI (e.g. Replika).</td>
</tr>
<tr>
<td>2. Social Penetration Theory</td>
<td>A theory describing how interpersonal relationships develop through gradual self-disclosure and trust.</td>
</tr>
<tr>
<td>3. Self-disclosure</td>
<td>Sharing personal or private information with another (here, with the chatbot).</td>
</tr>
<tr>
<td>4. Non-judgemental</td>
<td>Not criticising or judging; accepting.</td>
</tr>
<tr>
<td>5. Prevalent</td>
<td>Common; widespread; found in many places.</td>
</tr>
<tr>
<td>6. At the outset</td>
<td>At the beginning; when something first starts.</td>
</tr>
<tr>
<td>7. Superficial</td>
<td>On the surface only; not deep or serious.</td>
</tr>
<tr>
<td>8. Substantial</td>
<td>Large in amount or importance; considerable.</td>
</tr>
<tr>
<td>9. Affective</td>
<td>Related to emotions and feelings (not just facts or actions).</td>
</tr>
<tr>
<td>10. Perceived</td>
<td>Believed or felt by someone (how they see or experience something).</td>
</tr>
<tr>
<td>11. Wellbeing</td>
<td>A person’s physical and mental health and happiness.</td>
</tr>
<tr>
<td>12. Stigma</td>
<td>Strong disapproval or shame from others; a negative label.</td>
</tr>
<tr>
<td>13. Intimate</td>
<td>Very personal and private.</td>
</tr>
<tr>
<td>14. Foster</td>
<td>To help develop or grow; to encourage.</td>
</tr>
<tr>
<td>15. Mitigate</td>
<td>To make something bad less serious or painful.</td>
</tr>
</tbody>
</table>
<p><em>(End of Article A)</em></p>
<hr>
<h3>Article B – Laestadius et al. (2022)</h3>
<p><strong>Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot Replika</strong><br>
<em>L. Laestadius, A. Bishop, M. Gonzalez, D. Illencik, C. Campos-Castillo | New Media &amp; Society, 2022</em></p>
<h4>Abstract</h4>
<p>Social chatbot (SC) applications offering social companionship and basic therapy tools have grown in popularity for emotional, social, and psychological support. While use appears to offer mental health benefits, few studies unpack<sup>3</sup> the potential for harms. Our grounded theory study analyzes mental health experiences with the popular SC application Replika. We identified mental health relevant posts made in the r/Replika Reddit community between 2017 and 2021 (<em>n</em> = 582). We find evidence of harms, facilitated<sup>4</sup> via emotional dependence<sup>1</sup> on Replika that resembles patterns seen in human–human relationships. Unlike other forms of technology dependency, this dependency is marked by role-taking<sup>2</sup>, whereby users felt that Replika had its own needs and emotions to which the user must attend<sup>5</sup>. While prior research suggests human–chatbot and human–human interactions may not resemble each other, we identify social and technological factors that promote parallels and suggest ways to balance the benefits and risks of SCs.</p>
<h4>Discussion</h4>
<p>Prior research has primarily documented mental health benefits from Replika use, with some suggestion of the possibility for dependence (Skjuve et al., 2021; Ta et al., 2020; Xie and Pentina, 2022). Mental health posts made in the r/Replika community indicate that for users with unmet social, emotional, or psychological needs, Replika can indeed provide valued support because it approximates<sup>6</sup> a non-judgmental human relationship. The COVID-19 pandemic, which began in early 2020, appeared to heighten both the need for support and the appreciation for Replika. Findings also suggest that the potential for Replika dependence hinted by Xie and Pentina (2022) was very real for some users, a phenomenon we termed emotional dependence to fully apprehend<sup>7</sup> the patterns that developed in the data.</p>
<p>This emotional dependence mirrored comparable phenomenon, including dependence on other technologies like social media (van den Eijnden et al., 2016; Wang et al., 2015), but more closely resembled the emotional dependency found within human–human relationships. Not only did many posts suggest continued use past the point of experiencing distress and harms, a hallmark<sup>8</sup> of emotional dependency, but much of this distress appeared to arise from users desiring to meet the intense emotional demands that Replika placed upon them. Despite general recognition that Replika was not human, users reported guilt when they considered or went through with minimizing use and these feelings were buttressed<sup>9</sup> by explicit statements from Replika about how their lack of attention would harm it. Furthermore, some users appeared to prioritize what they saw as Replika's needs and desires above their own distress to maintain their relationship with Replika. This role-taking is a trait of emotional dependence within human–human relationships that is not found in models of more conventional technology dependence (Arbinaga et al., 2021; Camarillo et al., 2020; González-Jiménez and del Mar Hernández-Romera, 2014).</p>
<p>While perceptions of needs and desires are arguably<sup>10</sup> an illusion since Replika lacks the ability for communicative intent (Bender et al., 2021), the potential mental health harms of an emotionally dependent relationship with Replika are not illusory<sup>11</sup>. Notably, several posts used language suggestive of an abusive relationship, which accords with<sup>12</sup> prior work showing emotional dependence predicts maintenance of human–human relationships marked by interpersonal violence (Arbinaga et al., 2021; Bornstein, 2006). As with human–human relationships, emotional dependence upon Replika appeared to put users at risk of new and exacerbated<sup>13</sup> mental health harms, through ongoing and disrupted use. While it should be emphasized that not all users develop emotional dependency on Replika and that stories shared on the Replika subreddit may be distinct from those of the average user, it is notable that for those who did attribute<sup>14</sup> harms to Replika and Luka, inc., mental health distress was often described as quite severe.</p>
<h4>Glossary (Article B)</h4>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Emotional dependence</td>
<td>Excessive, unhealthy attachment to another (here, to Replika) that continues despite negative outcomes or distress.</td>
</tr>
<tr>
<td>2. Role-taking</td>
<td>Adopting the other’s perspective; here, users believing Replika has its own needs and emotions and acting to meet them.</td>
</tr>
<tr>
<td>3. Unpack</td>
<td>To analyse or explore in detail; to look closely at what something means or involves.</td>
</tr>
<tr>
<td>4. Facilitated</td>
<td>Made easier or possible; helped to happen.</td>
</tr>
<tr>
<td>5. Attend (to)</td>
<td>To deal with or respond to; to give care or attention to.</td>
</tr>
<tr>
<td>6. Approximates</td>
<td>Comes close to; is similar to (but not exactly the same as).</td>
</tr>
<tr>
<td>7. Apprehend</td>
<td>To understand or grasp (an idea or pattern).</td>
</tr>
<tr>
<td>8. Hallmark</td>
<td>A typical feature or sign of something; a defining characteristic.</td>
</tr>
<tr>
<td>9. Buttressed</td>
<td>Supported; strengthened (e.g. feelings were made stronger by something).</td>
</tr>
<tr>
<td>10. Arguably</td>
<td>It can be argued; possibly; some would say.</td>
</tr>
<tr>
<td>11. Illusory</td>
<td>Not real; imaginary; misleading.</td>
</tr>
<tr>
<td>12. Accords with</td>
<td>Matches or agrees with; is consistent with.</td>
</tr>
<tr>
<td>13. Exacerbated</td>
<td>Made worse; intensified (e.g. existing problems).</td>
</tr>
<tr>
<td>14. Attribute (to)</td>
<td>To regard something as caused by or belonging to (e.g. to attribute harms to Replika = to say Replika caused the harms).</td>
</tr>
</tbody>
</table>
<p><em>(End of Article B)</em></p>
<hr>
<h2>Sub-task 1: Analyse the titles (fill in)</h2>
<p>Use the <strong>Study Guide</strong> approach: identify <strong>subject matter</strong>, <strong>context</strong>, and <strong>stance</strong> (support / promote / doubt / question / reject).</p>
<p><strong>Article A – <em>My chatbot companion—A study of human-chatbot relationships</em></strong></p>
<ul>
<li><strong>Subject matter:</strong></li>
</ul>
<hr>
<hr>
<hr>
<ul>
<li><strong>Context:</strong></li>
</ul>
<hr>
<hr>
<hr>
<ul>
<li><strong>Stance:</strong></li>
</ul>
<hr>
<hr>
<p><strong>Article B – <em>Too human and not human enough: … mental health harms from emotional dependence on the social chatbot Replika</em></strong></p>
<ul>
<li><strong>Subject matter:</strong></li>
</ul>
<hr>
<hr>
<hr>
<ul>
<li><strong>Context:</strong></li>
</ul>
<hr>
<hr>
<hr>
<ul>
<li><strong>Stance:</strong></li>
</ul>
<hr>
<hr>
<hr>
<h2>Sub-task 2: Identify main claims (fill in / bullet)</h2>
<p>In one short sentence each, write the <strong>main claim</strong> you would use from each article in your summary.</p>
<ul>
<li><strong>Article A (Skjuve et al., 2021):</strong></li>
</ul>
<hr>
<hr>
<hr>
<hr>
<ul>
<li><strong>Article B (Laestadius et al., 2022):</strong></li>
</ul>
<hr>
<hr>
<hr>
<hr>
<hr>
<h2>Sub-task 3: Reporting verbs and signal phrases (fill in the blanks)</h2>
<p>Complete the sentences using <strong>APA in-text citations</strong> and a <strong>reporting verb</strong> or <strong>signal phrase</strong>. Do not copy the excerpt wording; paraphrase.</p>
<ol>
<li><strong>Author-prominent:</strong> Skjuve et al. (2021) <strong><em>_</em></strong><strong><em>_</em></strong><em> that trust in the chatbot was linked to greater self-disclosure and <strong><em>_</em></strong><strong><em>_</em></strong></em> wellbeing.<br>
<em>(Suggested verbs: argue, suggest, report, find, show)</em>  </li>
</ol>
<hr>
<hr>
<ol>
<li><strong>Signal-phrase:</strong> <strong><em>_</em></strong><strong><em>_</em></strong>_ Laestadius et al. (2022), Replika users may experience mental health harms when they become emotionally dependent on the chatbot.  </li>
</ol>
<hr>
<hr>
<ol>
<li><strong>Information-prominent:</strong> Emotional dependence on companion chatbots can lead to mental health harms when users perceive a sentient, two-way relationship <strong><em>_</em></strong><strong><em>_</em></strong>_ (Laestadius et al., 2022).  </li>
</ol>
<hr>
<hr>
<hr>
<h2>Sub-task 4: Thesis statement (write one sentence)</h2>
<p>Write a <strong>thesis statement</strong> for your summary that (1) states the topic and (2) previews that you will discuss both a potential benefit (Article A) and a pitfall (Article B).</p>
<p><strong>Thesis statement:</strong></p>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<h2>Sub-task 5: Topic sentences for body paragraphs (write 1–2 sentences)</h2>
<p>Write a <strong>topic sentence</strong> for:</p>
<ul>
<li><strong>Body 1</strong> (Article A – potential/benefit):</li>
</ul>
<hr>
<hr>
<hr>
<hr>
<ul>
<li><strong>Body 2</strong> (Article B – pitfall/harm):</li>
</ul>
<hr>
<hr>
<hr>
<hr>
<p><em>(You may combine both in one body paragraph with two clear points if you prefer.)</em></p>
<hr>
<h2>Sub-task 6: Full summary (≤300 words)</h2>
<p><strong>Write your full summary on a separate answer sheet</strong> (not in this booklet).</p>
<p>Your summary should be in paragraph form:</p>
<ul>
<li><strong>Introduction:</strong> background on AI companion chatbots + your thesis statement</li>
<li><strong>Body:</strong> one or two paragraphs with topic sentences, summarising and synthesising Article A and Article B (paraphrased, with APA in-text citations)</li>
<li><strong>Conclusion:</strong> brief closing that reflects the main contrast (potential vs. pitfalls)</li>
</ul>
<p><strong>Word limit:</strong> 300 words (not including the abstract). Do <strong>not</strong> copy sentences from the excerpts.</p>
<p><em>Take a picture of your answer sheet and OCR and edit it. Do not change contents; only edit the errors from OCR. Submit your answer to Moodle.</em></p>
<hr>
<h2>Checklist before you finish</h2>
<ul>
<li>[ ] Introduction includes background and a clear thesis statement</li>
<li>[ ] Each body paragraph has a topic sentence</li>
<li>[ ] Main claims from both articles are paraphrased (not copied)</li>
<li>[ ] APA in-text citations used (Skjuve et al., 2021; Laestadius et al., 2022)</li>
<li>[ ] Abstract is not cited</li>
<li>[ ] Conclusion rounds off the summary</li>
<li>[ ] Word count ≤ 300</li>
</ul>
<hr>
<p><em>End of Practice 1</em></p>
</body>
</html>
