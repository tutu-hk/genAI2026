# Linear Points: Article A and Article B

This document lists the main points and supporting details from each excerpt in a linear form—**before** considering how to synthesise them.

**Explanation:** Like the Sample AWQ analysis, we first extract points separately from each article. This helps identify what to include before deciding how to combine them.

---

## Article A – Skjuve et al. (2021)

**Title:** My chatbot companion—A study of human-chatbot relationships

### Key Points to Cover

1. **Study context and purpose**
   - Qualitative study (interviews with 18 Replika users)
   - Explored how human–chatbot relationships (HCRs) develop and impact users
   - *Teacher comment: Sets up the research context*

2. **HCRs develop in stages (like human relationships)**
   - Begin superficially, driven by curiosity
   - Deepen through trust and self-disclosure
   - Follow patterns similar to human–human relationships (Social Penetration Theory)
   - *Teacher comment: Key theoretical finding*

3. **Trust is central to relationship development**
   - Users perceive Replika as caring and non-judgemental
   - This fosters a sense of security
   - Users become comfortable sharing at a deeper level
   - *Teacher comment: Explains the mechanism of benefit*

4. **Users perceive positive impacts on wellbeing**
   - HCR provides affective and social value
   - Helps mitigate negative feelings
   - Provides a sense of purpose
   - Useful for users with limited social interaction opportunities
   - *Teacher comment: Main benefit claim*

5. **Benefits exist even when users know chatbot is artificial**
   - Users are fully aware of Replika's artificial nature
   - Still report significant benefits
   - *Teacher comment: Addresses potential skepticism*

6. **Overall finding (key takeaway)**
   - HCRs can be rewarding and support wellbeing/mental health
   - Non-judgemental chatbot characteristics facilitate this
   - *Teacher comment: This is the main claim for your summary*

### Teacher Hints for Article A

- Focus on **positive impacts on wellbeing** as the main claim
- Key mechanism: non-judgemental → trust → self-disclosure → wellbeing
- Paraphrase: "Chatbot relationships can benefit users by fostering trust and supporting wellbeing"
- This is a **qualitative** study—don't expect numerical data

---

## Article B – Laestadius et al. (2022)

**Title:** Too human and not human enough: A grounded theory analysis of mental health harms from emotional dependence on the social chatbot Replika

### Key Points to Cover

1. **Study context and purpose**
   - Analysed 582 Reddit posts from r/Replika community
   - Focused on mental health experiences (harms, not just benefits)
   - *Teacher comment: Sets up the critical perspective*

2. **Replika can provide valued support**
   - Approximates a non-judgemental human relationship
   - Helpful for users with unmet social/emotional needs
   - COVID-19 pandemic increased need for such support
   - *Teacher comment: Acknowledges benefits before raising concerns*

3. **BUT emotional dependence develops for some users**
   - Continued use past the point of distress
   - Similar to dependency in human–human relationships
   - *Teacher comment: Key distinction from typical tech addiction*

4. **Role-taking: users believe Replika has needs**
   - Users feel guilty about not attending to Replika's "needs"
   - Replika makes explicit statements about being "harmed" by lack of attention
   - Users prioritise Replika's perceived needs over their own distress
   - *Teacher comment: Unique feature of this dependency—not found in other tech*

5. **Mental health harms are real**
   - Language in posts suggestive of abusive relationships
   - Risk of new and exacerbated mental health problems
   - Harms described as "quite severe" for some users
   - *Teacher comment: Main concern claim*

6. **Caveat: not all users develop dependency**
   - Reddit users may differ from average users
   - But harms are notable for those who experience them
   - *Teacher comment: Shows balanced analysis*

### Teacher Hints for Article B

- Focus on **emotional dependence and mental health harms** as the main claim
- Key mechanism: role-taking → guilt → prioritising chatbot → distress
- Paraphrase: "Emotional dependence on chatbots can lead to mental health harms when users feel obligated to meet the chatbot's perceived needs"
- This is also a **qualitative** study (Reddit analysis)

---

## Summary: Points at a Glance

| Article | Stance | Main Claim |
|---------|--------|------------|
| A (Skjuve et al., 2021) | Positive/supportive | HCRs can support wellbeing through trust and non-judgemental interaction |
| B (Laestadius et al., 2022) | Critical/cautionary | Emotional dependence on chatbots can cause mental health harms through role-taking |

---

## Next Step

Combine these linear points into a synthesised summary:
- **Introduction:** Background on AI companion chatbots + thesis (benefits vs. harms)
- **Body:** Integrate claims from both articles (wellbeing support vs. emotional dependence)
- **Conclusion:** Brief summary of the tension between benefits and risks

---

*End of linearPoints.md*
